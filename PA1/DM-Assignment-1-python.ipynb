{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc5c302",
   "metadata": {},
   "source": [
    "# Data Mining Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6ed629",
   "metadata": {},
   "source": [
    "## Student Details\n",
    "\n",
    "Student Name and ID of the member submitting the assignment: \n",
    "\n",
    "Student Name and ID of the remaining members: \n",
    "\n",
    "Notes:\n",
    "When submitting, fill your name and ID in this cell. Note that this is a markdown cell!<br>\n",
    "Do not make any changes in the dataset file and do not rename the 'database.csv'.\n",
    "<br> Rename your submission file to <b> 'yourLastName_Last4digitsofyourID_PA1.ipynb' </b>. \n",
    "<br> Do not to forget to cite any external sources used by you. \n",
    "**5 points per question will be deducted incase you fail to do so**\n",
    "<br>**DO NOT DELETE THIS CELL**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7616a85",
   "metadata": {},
   "source": [
    "## Assignment Details\n",
    "\n",
    "In this assignment, you will conduct a guided exploration over the given dataset.\n",
    "\n",
    "You will prepare a **report** with the following outline for each one of the dataset. Look at the following Example.\n",
    "\n",
    "1.\tIntroduction\n",
    "\n",
    "2.\tRetrieving the Data\n",
    "\n",
    "3.\tGlimpse of Data\n",
    "\n",
    "4.\tCheck for missing data\n",
    "\n",
    "5.\tData Exploration\n",
    "\n",
    "\n",
    "You will learn and use some of the most common exploration/aggregation/descriptive operations. This should also help you learn most of the key functionalities in Python/Pandas, Weka and R. DO Task 1, Task 2, Task 3, Task 4 using Python/Pandas, Weka, R\n",
    " \n",
    "**Out of the 3 datasets listed below:**\n",
    "\n",
    "**1. Weather dataset should be solved using Python in Jupyter notebook only.**\n",
    "\n",
    "**2. Surgical dataset using WEKA**\n",
    "\n",
    "**3. Healthcare_stroke_dataset using R**\n",
    "\n",
    "\n",
    "You will also learn how to use visualization libraries to identify patterns in data that will help in your further data analysis. You will also explore most popular chart types and how to use different libraries and styles to make your visualizations more attractive.\n",
    "\n",
    "**Each code visualization and plotted needs to be explained in the 4 to 5 lines**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfaa707",
   "metadata": {},
   "source": [
    "# Dataset Details\n",
    "\n",
    "In this assignment, you will work on 1) \n",
    "weather_dataset.csv\n",
    "The columns of the data-set are:\n",
    "\n",
    "* Date\n",
    "* Time\n",
    "* Temp Humidity Index   \n",
    "* Outside Temperature\n",
    "* WindChill\n",
    "* Hi Temperature\n",
    "* Low Temperature\n",
    "* Outside Humidity\n",
    "* DewPoint\n",
    "* WindSpeed\n",
    "* Hi\n",
    "* Wind Direction\n",
    "* Rain\n",
    "* Barometer\n",
    "* Inside  Temperature\n",
    "* Inside  Humidity\n",
    "* ArchivePeriod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b98b09",
   "metadata": {},
   "source": [
    "## Required Python Packages\n",
    "You will only use the packages imported below in this assignment. \n",
    "<br>**Do NOT import any new packages without confirming with the TA.**\n",
    "<br>20 points will be deducted from the assignment if any library is used except provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c424b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# special IPython command to prepare the notebook for matplotlib\n",
    "%matplotlib inline \n",
    "\n",
    "#Array processing\n",
    "import numpy as np\n",
    "#Data analysis, wrangling and common exploratory operations\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from itertools import chain\n",
    "\n",
    "#For visualization. Matplotlib for basic viz and seaborn for more stylish figures\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f859bf04",
   "metadata": {},
   "source": [
    "# Reading Dataset\n",
    "The Python code below reads the weather dataset into a Pandas data frame with the name df_data. \n",
    "For this code to work, the file 'database.csv' must be in the same folder as this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5543d412",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'weather_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z4/fkls1k917_51fhgf9jbrkgd40000gn/T/ipykernel_71859/236924682.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#read the csv file into a Pandas data frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weather_dataset.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#return the first 5 rows of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'weather_dataset.csv'"
     ]
    }
   ],
   "source": [
    "#read the csv file into a Pandas data frame\n",
    "df_data = pd.read_csv('weather_dataset.csv', encoding='latin1')\n",
    "\n",
    "#return the first 5 rows of the dataset\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9538476",
   "metadata": {},
   "source": [
    "# Task 1: Statistical Exploratory Data Analysis\n",
    "Let us start with getting know the dataset. Your first task will be to get some basic information by using Pandas features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d283dcc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#For each task below, look for a Pandas function to do the task.\n",
    "#Replace None in each task with your code.\n",
    "\n",
    "# 1 points\n",
    "#Task 1-a: Print the details of the df_data data frame (information such as number of rows,columns, name of columns, etc)\n",
    "print (\"Task 1-a: Details of df_data data frame are: \\n\", ) \n",
    "\n",
    "# 1 points\n",
    "#Task 1-b: Find the number of rows and columns in the df_data data frame.\n",
    "print (\"Task 1-b: Number of rows:%s and number of columns:%s\"  ) \n",
    "\n",
    "# 1 points\n",
    "#Task 1-c: Print the descriptive detail (count, unique, top, freq etc) for 'educational-num' column of the df_data \n",
    "print (\"Task 1-c: Descriptive details of 'educational-num' column are\\n\"))\n",
    "\n",
    "# 1 points\n",
    "#Task 1-d: Print the average temp for each day\n",
    "print(\"Task 1-d: The average temp for each day:\")\n",
    "\n",
    "# 1 points\n",
    "#Task 1-e: Print the average temp for each week\n",
    "print(\"Task 1-e: The average temp for each day:\")\n",
    "\n",
    "# 1 points\n",
    "#Task 1-f: What is the maximum temperature difference each day for all the days of the months?\n",
    "print(\"Task 1-f: Maximum temperature difference each day for all the days of the months:\")\n",
    "\n",
    "# 1 points\n",
    "#Task 1-h: What is the minium temperature difference each day for all the days of the months?\n",
    "print(\"Task 1-h: Minium temperature difference each day for all the days of the months:\")\n",
    "\n",
    "#Task 1-i: Display all the unique values for each column.\n",
    "print(\"Task 1-i: The unique values for each column are:\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5cb345",
   "metadata": {},
   "source": [
    "# Task 2: Aggregation & Filtering & Rank\n",
    "In this task, we will perform some very high level aggregation and filtering operations. \n",
    "Then, we will apply ranking on the results for some tasks. \n",
    "Pandas has a convenient and powerful syntax for aggregation, filtering, and ranking. \n",
    "DO NOT write a for loop. Pandas has built-in functions for all tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ef29be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 points\n",
    "# Task 2-A: Generate a Outside_Temperature.txt file containing the answers to the following questions: \n",
    "# Using the “Outside Temperature” values: \n",
    "# a. What is the average time of hottest daily temperature (over month); \n",
    "# b. What time of the day is the most commonly occurring hottest time; \n",
    "# c. Which are the Top Ten hottest times on distinct days, preferably sorted by date order.\n",
    "\n",
    "\n",
    "# 20 points\n",
    "#Task 2-B: Using the ‘Hi Temperature’ values produce a “Hi_Temperature.txt” file containing all of the Dates and Times\n",
    "# where the “Hi Temperature” was within +/- 1 degree of 22.3 or \n",
    "# the “Low Temperature” was within +/- 0.2 degree higher or lower of 10.3 over the first 9 days of June\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f930e6d",
   "metadata": {},
   "source": [
    "# Task 3: Visualization\n",
    "In this task, you will perform a number of visualization tasks to get some intuition about the data. Visualization is a key component of exploration. You can choose to use either Matplotlib or Seaborn for plotting. The default figures generated from Matplotlib might look a bit ugly. So you might want to try Seaborn to get better figures. Seaborn has a variety of styles. Feel free to experiment with them and choose the one you like. We have earmarked 10 points for the aesthetics of your visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ce3127",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.set(font_scale = 1.3)\n",
    "\n",
    "# 5 points\n",
    "# Task 3-a: Visulalize the temperature for each month  \n",
    "# Think of a way to nicely visualize all the temperature and provide detailed explaination \n",
    "#########################begin code for Task 3-a\n",
    "\n",
    "\n",
    "\n",
    "#########################end code for Task 3-a\n",
    "\n",
    "# 15 points\n",
    "# Task 3-b: Display the time period on a bar plot which has highest temperature for the first 5 days of every month\n",
    "# provide detailed explaination \n",
    "#########################begin code for Task 3-b \n",
    "\n",
    "\n",
    "#########################end code for Task 3-b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd033d5e",
   "metadata": {},
   "source": [
    "# Task 4: \n",
    "Find out an 'interesting' information from the dataset. Create two visualization for it and explain in a 4 to 5 lines your valid reasoning. Do not copy paste from another team member.\n",
    "This task is worth 20 points. Your result will be judged based on the uniqueness and quality of your work (having a meaningful result and an aesthetic visualization). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4cc929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################begin code for Task 4\n",
    "\n",
    "#########################end code for Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b14924",
   "metadata": {},
   "source": [
    "## Report for Python\n",
    "Report Explanation\n",
    "Create a report in a pdf file explaining the answer for task 2, 3 and 4<br>\n",
    "Note: the more detailed explanation the better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209c8bde",
   "metadata": {},
   "source": [
    "## Rubricks\n",
    "\n",
    "Task 1: 8 points<br>\n",
    "Task 2: 40 points<br>\n",
    "Task 3: 20 points<br>\n",
    "Task 4: 20 points<br>\n",
    "Report : 12 points<br>\n",
    "------------------------------------\n",
    "Total : 100 points<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
